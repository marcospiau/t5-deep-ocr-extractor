# Projeto final IA376J - Desafio SROIE Task 3 - Key Information Extraction from Scanned Receipts

# Introdu√ß√£o

Este reposit√≥rio cont√©m c√≥digo para solucionar a `Task 3 - Key Information Extraction from Scanned Receipts` do `ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction`. A descri√ß√£o completa do desafio e tarefas completas pode ser encontrada em [Tasks - ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction](https://rrc.cvc.uab.es/?ch=13&com=tasks). Esta tarefa busca extrair campos relevantes [‚Äúaddress‚Äù, ‚Äúcompany‚Äù, ‚Äútotal‚Äù, ‚Äúdate‚Äù] de receipts escaneados. Nossa solu√ß√£o √© baseada em extrair informa√ß√µes textuais das imagens utilizando o Google Vision OCR, e ent√£o alimentar um modelo T5 com esses dados para extrair os campos relevantes.

Todos os experimentos est√£o registrados no Neptune Logger, e podem ser consultados nesse link [link](https://ui.neptune.ai/marcospiau/final-project-ia376j-1/experiments?viewId=7b690bc2-f1ea-499d-81f2-30a5c0208c04). ALgumas bibliotecas importantes utilizadas no projeto s√£o:
* pytorch-lightning: redu√ß√£o de boilerplate pytorch e configura√ß√£o do loop de treino e eval
* Hugging Face ü§ó transformers: modelos T5
* gin-config: configura√ß√£o dos experimentos
* Neptune: experiment tracking

# Final Project IA376J - SROIE Task 3 Challenge - Key Information Extraction from Scanned Receipts

# Introduction

This repository contains code to solve the `Task 3 - Key Information Extraction from Scanned Receipts` from the `ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction`. The complete description of the challenge and tasks can be found at [Tasks - ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction](https://rrc.cvc.uab.es/?ch=13&com=tasks). This task aims to extract relevant fields [‚Äúaddress‚Äù, ‚Äúcompany‚Äù, ‚Äútotal‚Äù, ‚Äúdate‚Äù] from scanned receipts. Our solution is based on extracting textual information from the images using Google Vision OCR, and then feeding a T5 model with this data to extract the relevant fields.

All experiments are logged on Neptune and can be found at this link [link](https://ui.neptune.ai/marcospiau/final-project-ia376j-1/experiments?viewId=7b690bc2-f1ea-499d-81f2-30a5c0208c04). Some key libraries used in the project are:
* pytorch-lightning: for reducing pytorch boilerplate and configuring the training and evaluation loop
* Hugging Face ü§ó transformers: for T5 models
* gin-config: for experiment configuration
* Neptune: for experiment tracking


# How this repository is structured
```
.
|-- LICENSE
|-- README.md
|-- notebooks <<<<< Jupyter Notebooks
|   |-- draft <<<<< draft notebooks
|   |-- select_best_sroie_checkpoints_t5_ocr_baseline_initial_finetune.ipynb <<<<< notebook with initial selection of the best models
|   `-- sroie_t5_ocr_baseline_prepare_competition_submission.ipynb <<<<< notebook for creating files for competition submission
|-- setup.py
`-- src
    |-- __init__.py
    |-- data <<< codes that handle data
    |   |-- __init__.py
    |   |-- google_vision_ocr_extraction.py <<<< code for OCR extraction using Google Vision
    |   |-- google_vision_ocr_parsing.py <<< parsing of OCRs generated by Google Vision
    |   `-- sroie
    |       |-- __init__.py
    |       `-- t5_ocr_baseline.py <<<< Pytorch Dataset used in the models
    |
    |-- evaluation <<<< codes and scripts for model evaluation
    |   |-- __init__.py
    |   |-- save_experiment_predictions_t5_ocr_baseline.py <<<<< 
    |   |-- save_preds_t5_final_finetuning.sh
    |   |-- save_preds_t5_initial_finetuning.sh
    |   `-- sroie_eval_utils.py
    |-- metrics.py <<<< metrics used
    |-- models <<< model codes
    |   |-- __init__.py
    |   |-- gin <<<< gin files with configurations of all conducted experiments
    |   |   |-- README.md
    |   |   |-- best_t5_models_defaults.gin <<< default gin config for final model training (trained on all labeled data with the best hyperparameter combinations)
    |   |   |-- defaults.gin <<<< default gin config for initial finetune experiments
    |   |   |-- generate_t5_default_finetune_gin_configs.py <<<<< script that generates the gin config files for the initial finetune experiments
    |   |   |-- t5_best_models_finetune <<<< gin configs of the final models (trained on all labeled data with the best hyperparameter combinations)
    |   |   |-- t5_default_finetune <<<<< gin config files for the initial finetune experiments
    |   |-- gin_configurables.py <<<< extension of classes for gin configurables
    |   |-- gin_trainer_t5_ocr_baseline.py <<<< main model training script
    |   |-- past_scripts <<<< old scripts
    |   |-- t5_ocr_baseline.py <<<< Pytorch Lightning model module code
    |   `-- utils.py 
    `-- utils.py
```
